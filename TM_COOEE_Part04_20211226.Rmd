---
title: "Analysis of the Corpus of Oz Early English - Part 4: Topic Modeling"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: Bibliography.bib
link-citations: yes
---

# Introduction

This document shows an analysis of Corpus of Oz Early English  (COOEE) [@fritz2004cooee]. 

## Aims

* Find keywords

* Check for distribution of keyterms by date (mosaic plot) (part 2)

* Create network of keyterms (network analysis) (part 2)

* **Find topics (topic modeling)**

* Error analysis (misspelled words, words not in dictionary) (part 4)

# Set Up

In a first step, the session is prepared by installing packages.


```{r ampause_01_01, eval = F, message=FALSE, warning=FALSE}
# load packages
install.packages("tidyverse")
install.packages("tidytext")
install.packages("tidyr")
install.packages("tm")
install.packages("tokenizers")
install.packages("qdap")
install.packages("textstem")
install.packages("corpus")
install.packages("quanteda.textmodels")
install.packages("seededlda")
install.packages("lubridate")
```

Now, we activate the packages, set options, load relevant functions, and defining the path to the data.

```{r}
# set options
options(stringsAsFactors = F)
options(scipen = 999)
# load packages
library(tidyverse)
library(tidytext)
library(tidyr)
library(tm)
library(tokenizers)
library(qdap)
library(textstem)
library(corpus)
library(quanteda)
library(quanteda.textmodels)
library(seededlda)
library(lubridate)
# for pos-tagging objects in R
source("D:\\R/POStagObject.R") 
```


In a next step, we load and process the data.

```{r}
# cooee
cooee_clean  <- base::readRDS(file = here::here("data", "cooeed_clean.rda"))
# inspect
str(cooee_clean)
```

```{r}
# define stopword search pattern
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
custregex <- c("\\b|\\bone\\b|\\b[:alnum:]{1,3}\\b|\\b[0-9]{1,3}[a-z]{2,2}\\b|\\balso\\b|\\bmust\\b|\\bmany\\b|\\bmuch\\b|\\bmevery\\b")
stopwords_regex = paste0('\\b', stopwords_regex, custregex)
# clean corpus
cooee_clean <- cooee_clean %>%
  dplyr::mutate(Text_semiclean = stringr::str_remove_all(Text, stopwords_regex),
                Text_semiclean = stringr::str_squish(Text_semiclean))
# inspect
head(cooee_clean)
```


prepare data

```{r}
cooee_sent <- tokenize_sentence(cooee_clean$Text_semiclean) %>%
  unlist() %>%
  tolower %>%
  stemDocument()
# check
length(cooee_sent); head(cooee_sent)
```


```{r}
# convert to corpus
cooee_corpus <- corpus(cooee_sent)
```


# Topic Modelling


Create corpus and DTM

```{r}
toks_cooee <- tokens(cooee_corpus, 
                    remove_punct = TRUE, 
                    remove_numbers = TRUE, 
                    remove_symbol = TRUE)
dfmat_cooee <- dfm(toks_cooee) %>% 
              dfm_trim(min_termfreq = 0.2, 
                       termfreq_type = "quantile",
                       max_docfreq = 0.2, 
                       docfreq_type = "prop")
# inspect
dfmat_cooee[1:10, 1:10]
```



```{r}
set.seed(1234)
tmod_lda <- seededlda::textmodel_lda(dfmat_cooee, k = 6)
readr::write_delim(as.data.frame(terms(tmod_lda, 10)), here::here("tables", "topic_keys.txt"), delim = "\t")
# inspect
terms(tmod_lda, 10)
```

```{r}
# semisupervised LDA
dict <- dictionary(list(family = c("family", "dear", "home", "mother",
                                   "father", "son", "daugther"),
                        journey = c("ship", "wind", "ocean", "travel", "arriv", "board"),
                        landscape = c("creek", "river", "australia", "hill", "water"),
                        exploration = c("camp", "camel", "hors*"),
                        indiginous = c("black", "nativ*", "aborig*", "chief"),
                        employment = c("work", "money", "pay", "week", "good", "gold")))
tmod_slda <- textmodel_seededlda(dfmat_cooee, dict, residual = TRUE, min_termfreq = 10)
terms(tmod_slda)
```

save keyterms

```{r}
readr::write_delim(as.data.frame(terms(tmod_slda)), here::here("tables", "topic_keys.txt"), delim = "\t")
# inspect
terms(tmod_slda, 10)
```


```{r}
topics(tmod_slda)
```




```{r}
length(topics(tmod_slda))
```
```{r}
head(topics(tmod_slda), 20)
```

# Topic by period

create index of how many sentences are in each letter

```{r}
cooee_idx <- sapply(cooee_clean$Text_semiclean, function(x){
  x <- tokenize_sentence(x)
  x <- sapply(x, function(y){ length(y) })
})
cooee_idx <- as.vector(cooee_idx)
# inspect
head(cooee_idx)
```

generate data frame with topic for each sentence plus period

```{r}
Letters <- rep(cooee_clean$Nr, cooee_idx)
Date <- rep(cooee_clean$YearWriting, cooee_idx)
Period <- rep(cooee_clean$Datecat, cooee_idx)
Topics <- topics(tmod_slda)
Id <- 1:length(Topics)
# generate df
cooee_df <- data.frame(Id, Letters, Date, Period, Topics) %>%
  dplyr::group_by(Period, Topics) %>%
  dplyr::summarise(Freq = n()) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Topics = dplyr::case_when(Topics == "family" ~ "Topic1_family",
                                          Topics == "journey" ~ "Topic2_journey",
                                          Topics == "landscape" ~ "Topic3_landscape",
                                          Topics == "exploration" ~ "Topic4_exploration",
                                          Topics == "indiginous" ~ "Topic5_indiginous",
                                          Topics == "employment" ~ "Topic6_eployment",
                                          Topics == "other" ~ "Topic7_other")) %>%
  tidyr::drop_na() %>%
  dplyr::group_by(Period) %>%
  dplyr::mutate(Sum = sum(Freq),
                Percent = round(Freq/Sum*100, 1))
# save data
readr::write_delim(cooee_df, here::here("tables", "cooee_df.txt"), delim = "\t")
# inspect
head(cooee_df, 10)
```

plot

```{r}
cooee_df %>%
  ggplot(aes(x = Period, y = Percent, group = Topics, fill = Topics)) +
  geom_bar(stat = "identity", position="stack") +
  #scale_fill_grey() +
  scale_fill_brewer(palette="Dark2") +
  theme(legend.position="top",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(angle = 0, size =10)) +
  scale_y_continuous(name = "Proportion (%)", 
                   breaks = seq(0, 100, 25), 
                   labels = seq(0, 100, 25), 
                   limits = c(0, 105))
ggsave(file = here::here("images", "topic_cooee_col.png"), 
         height = 4,  width = 7.5, dpi = 320)
```


# Outro

```{r}
sessionInfo()
```


# References

