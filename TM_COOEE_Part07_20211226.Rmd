---
title: "Analysis of the Corpus of Oz Early English - Part 3: Keyword Extraction"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: Bibliography.bib
link-citations: yes
---

# Introduction

This document shows an analysis of Corpus of Oz Early English  (COOEE) [@fritz2004cooee]. 

## Aims

* **Find keywords**

* **Check for distribution of keywords by date (mosaic plot)**

* **Create network of keywords (network analysis)**

* Find topics (topic modeling) (part 3)

* Error analysis (misspelled words, words not in dictionary) (part 4)

# Set Up

In a first step, the session is prepared by installing packages.


```{r ampause_01_01, eval = F, message=FALSE, warning=FALSE}
# load packages
install.packages("tidyverse")
install.packages("tidytext")
install.packages("tidyr")
install.packages("tm")
install.packages("tokenizers")
install.packages("qdap")
install.packages("textstem")
install.packages("corpus")
install.packages("quanteda")
install.packages("quanteda.textstats")
install.packages("ngram")
```

Now, we activate the packages, set options, load relevant functions, and defining the path to the data.

```{r}
# set options
options(stringsAsFactors = F)
options(scipen = 999)
# load packages
library(tidyverse)
library(tidytext)
library(tidyr)
library(tm)
library(tokenizers)
library(qdap)
library(textstem)
library(corpus)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
library(ngram)
# for pos-tagging objects in R
source("D:\\R/POStagObject.R") 
```


In a next step, we load and process the corpus data.


```{r}
# cooee
cooee_clean  <- base::readRDS(file = here::here("data", "cooeed_clean.rda"))
# keywords
sigkeywords  <- base::readRDS(file = here::here("data", "sigkeywords.rda"))
# period keys
period_keys  <- base::readRDS(file = here::here("data", "period_keys.rda"))
# inspect
head(cooee_clean); head(sigkeywords)
```


reduce sig keywords

```{r}
sigkeywords <- sigkeywords %>%
  dplyr::arrange(-phi) %>%
  dplyr::filter(phi > 0.0175)
# inspect
head(sigkeywords); nrow(sigkeywords)
```



# Network

extract uni- to trigrams in cooee

```{r}
# tokenize, tolower, remove stopwords and create ngrams
cooee_toks <- tokens(cooee_clean$Text_clean) 
cooee_tokngrms <- tokens_ngrams(cooee_toks, n = 1)
cooee_ngrmfreq <- cooee_clean %>% 
  group_by(id) %>%
  tidytext::unnest_ngrams(cooee_tokngrms, Text_clean, n = 1, n_min = 1, ngram_delim = "_") %>% 
  dplyr::count(cooee_tokngrms) %>%
  dplyr::rename("letter" = colnames(.)[1],
                "word" = colnames(.)[2],
                "freq" = colnames(.)[3]) %>%
  dplyr::filter(word %in% sigkeywords$Word) %>% 
  tidyr::spread(word, freq) %>% 
  replace(is.na(.), 0)
# remove letter
cooee_ngrmfreq <-cooee_ngrmfreq[, 2:ncol(cooee_ngrmfreq)]
# inspect
cooee_ngrmfreq
```

create dfm

```{r}
# create a document feature matrix
cooee_dfm <- quanteda::as.dfm(cooee_ngrmfreq)
# create feature co-occurrence matrix
cooee_fcm <- quanteda::fcm(cooee_dfm)
# inspect data
head(cooee_fcm)
```

generate network

```{r}
cnet <- quanteda.textplots::textplot_network(cooee_fcm, 
                                     min_freq = .5, 
                                     edge_alpha = 0.25, 
                                     edge_color = "gray50",
                                     vertex_labelsize = log(rowSums(cooee_fcm))/3,
                                     vertex_size = .5,
                                     max.overlaps = max.overlaps*2 )
ggsave(file = here::here("images", "net_cooee.png"), 
         height = 4,  width = 6, dpi = 320)
# inspect
cnet
```



# Outro

```{r}
sessionInfo()
```


# References